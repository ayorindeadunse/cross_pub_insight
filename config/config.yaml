llm:
  model_name: "gpt-4
  temperature: 0.2
  max_tokens: 1500

repo_parser:
  file_types: ["README.md", "requirements.txt", "pyproject.toml"]

output:
  directory: "output/"
  