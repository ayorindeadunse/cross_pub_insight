# Cross Publication Insight Assistant

**Cross Publication Insight Assistant** is a multi-agent, LLM-powered system designed to analyze, compare, and summarize trends across AI/ML GitHub repositories or research publications.

It supports deep repository parsing, LLM-based and semantic trend extraction, fact-checking, summarization, and user-defined aggregation queries such as:
- â€œWhat % of these projects use LangGraph?â€
- â€œHow do CrewAI and LangChain projects differ?â€
- â€œShow me projects that use vector DBs.â€

---


## Features

- **Multi-Agent Architecture** using LangGraph
  - **Project Analyzer Agent**: Inspects repo content and structure.
  - **Trend Aggregator Agent**: Extracts trends via LLM or semantic embeddings (fallback).
  - **Comparison Agent**: Highlights similarities and differences.
  - **Fact Checker Agent**: Validates the accuracy of LLM outputs.
  - **Aggregate Query Agent**: Answers cross-repo questions (e.g., tool usage).
  - **Summarizer Agent**: Produces human-readable insights.

-  **LangGraph Orchestration** with HITL (Human-in-the-loop) fallback at the pre-summary step.
-  **Custom LLM Prompting** using configurable templates.
-  **Trend Extraction via Two Modes**:
  - LLM-based trend synthesis.
  - Embedding-based fallback via `SentenceTransformers`.

-  **CLI Usage** with repo URLs or local paths.
-  **Easily Extendable** for evaluation metrics, publication ingestion, or communication protocols (e.g., MCP).

---

## Quickstart

### 1. Install dependencies
```bash
pip install -r requirements.txt

```

## Run the Agent
python3 main.py <primary_repo> <comparison_repo1> [comparison_repo2 ...] --query "What % use LangGraph?"

## Options

--query: (Optional) Ask a cross-repository question.

--no-hitl: (Optional) Run without human-in-the-loop intervention.

Example: python3 main.py https://github.com/user/project-a https://github.com/user/project-b --query "Which uses vector DBs?"


## Project Structure
<pre lang="markdown"> ### ğŸ“ Project Structure ```text . â”œâ”€â”€ agents/ # All agent definitions â”‚ â”œâ”€â”€ project_analyzer.py â”‚ â”œâ”€â”€ llm_trend_agent.py â”‚ â”œâ”€â”€ trend_aggregator.py â”‚ â”œâ”€â”€ comparison_agent.py â”‚ â”œâ”€â”€ fact_checker.py â”‚ â””â”€â”€ summarize_agent.py â”‚ â”œâ”€â”€ tools/ # Supporting tools/utilities â”‚ â”œâ”€â”€ semantic_trend_detector.py â”‚ â”œâ”€â”€ repo_parser.py â”‚ â”œâ”€â”€ comparison_tool.py â”‚ â””â”€â”€ hitl_intervention.py â”‚ â”œâ”€â”€ orchestrator/ â”‚ â””â”€â”€ orchestrator.py # LangGraph state orchestrator â”‚ â”œâ”€â”€ config/ â”‚ â”œâ”€â”€ config.yaml # LLM and model settings â”‚ â””â”€â”€ prompts/ # Custom prompt templates â”‚ â”œâ”€â”€ utils/ # Logging, config loader, HITL logic, etc. â”‚ â”œâ”€â”€ main.py # CLI entrypoint â”œâ”€â”€ README.md â”œâ”€â”€ LICENSE.md â”œâ”€â”€ requirements.in â”œâ”€â”€ requirements.txt â”œâ”€â”€ .env # Local environment variables â””â”€â”€ .env-example # Sample .env template ``` </pre>


## Tooling Used
 - LangGraph

 - SentenceTransformers (all-MiniLM-L6-v2)

 - Local or OpenAI LLMs

 - Jinja2 + YAML prompt configs

 - HITL prompt injection for summary verification


 ## Configuration

 Edit the config/config.yaml file to set:

- LLM model and type (local, openai, etc.)

- Trend detection thresholds

- Prompt paths and overrides

- HITL toggle

